{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c97f1fc2-1478-4f4e-91ac-4122b0e9261a",
   "metadata": {},
   "source": [
    "# A demonstation of synthetic handwritten image generation using variation autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908afb5f-dcd4-43ec-b412-fc047a2ff184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.vae import VAE\n",
    "from models.cvae import CVAE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce79653f-26b6-42e0-b699-1a0db1467f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aeb6b3-ffe0-4fbb-99f0-8d1748780c72",
   "metadata": {},
   "source": [
    "# Using VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1fd8f5d-ab31-4a51-a346-7416c55991df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (fc_mu): Linear(in_features=3136, out_features=20, bias=True)\n",
       "    (fc_logvar): Linear(in_features=3136, out_features=20, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (fc): Linear(in_features=20, out_features=6272, bias=True)\n",
       "    (deconv1): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (deconv2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (deconv3): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained model weights\n",
    "path = \"outputs/vae epoch_3 lr_0.001 bsize_64/weights.pth\"\n",
    "model = VAE().to(device)\n",
    "model.load_state_dict(torch.load(path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e7339-aace-4c32-9d9b-60b6e0ed9091",
   "metadata": {},
   "source": [
    "# Using Conditional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517a1f68-68fe-47cb-aff7-41ed06cd36f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVAE(\n",
       "  (encoder): Encoder(\n",
       "    (conv1): Conv2d(11, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (fc_mu): Linear(in_features=3136, out_features=20, bias=True)\n",
       "    (fc_logvar): Linear(in_features=3136, out_features=20, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (fc): Linear(in_features=30, out_features=6272, bias=True)\n",
       "    (deconv1): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (deconv2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (deconv3): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained model weights\n",
    "path = \"outputs/conditional_vae epoch_3 lr_0.001 bsize_64/weights.pth\"\n",
    "model = CVAE(num_classes=10).to(device) # 10 digit classes of the MNIST dataset\n",
    "model.load_state_dict(torch.load(path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7d9757-e890-4131-abc8-8ac438289a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
